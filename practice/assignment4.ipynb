{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1186qClifTlAds1YgL6qO-WqiI7Xnd6v3",
      "authorship_tag": "ABX9TyO4e698lUAHIYlWEBNJbQ/T"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn5jUj5M6WgZ",
        "colab_type": "text"
      },
      "source": [
        "### 1. Load training / validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yttwiwiM6dGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "data_root = './data/horse-or-human'\n",
        "\n",
        "# define vectorize transformer\n",
        "class VectorizeTransform:\n",
        "    def __call__(self, img):\n",
        "        return torch.reshape(img, (-1, ))\n",
        "\n",
        "# compose image transformer\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    VectorizeTransform()    # for vectorizing input image\n",
        "])\n",
        "\n",
        "# load training dataset\n",
        "train_data_path = data_root + '/train'\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=2048,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# load validation dataset\n",
        "valid_data_path = data_root + '/validation'\n",
        "valid_dataset = torchvision.datasets.ImageFolder(root=valid_data_path, transform=transform)\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=2048,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMGbwXRi700K",
        "colab_type": "text"
      },
      "source": [
        "### 2. Make full batch from training / validation dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l11h0tnq8TZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_full_batch(dataloader):\n",
        "  x = torch.tensor([])\n",
        "  y = torch.tensor([], dtype=torch.long)\n",
        "\n",
        "  for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
        "    x = torch.cat([x, x_batch], dim=0)\n",
        "    y = torch.cat([y, y_batch], dim=0)\n",
        "\n",
        "  y = torch.reshape(y, (-1, 1))\n",
        "\n",
        "  return x, y\n",
        "\n",
        "# make full batch data\n",
        "x_train, y_train = make_full_batch(train_loader)\n",
        "x_valid, y_valid = make_full_batch(valid_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShiCJ57cYPU5",
        "colab_type": "text"
      },
      "source": [
        "### 3. Define model and functions for learning neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q56TZ6yYTnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "# initialize weight according to activation type and fan in/out size\n",
        "def initialize_weight(activation_type, fan_in, fan_out):\n",
        "  base = torch.randn(fan_out, fan_in)\n",
        "\n",
        "  coefficient = 0\n",
        "  if activation_type in ['sigmoid', 'tanh']:\n",
        "    # use xavier initializer\n",
        "    coefficient = math.sqrt(1 / fan_in)\n",
        "  elif activation_type in ['relu', 'lrelu']:\n",
        "    # use he initializer\n",
        "    coefficient = math.sqrt(2 / fan_in)\n",
        "  else:\n",
        "    # cannot initialize weight because activation type is invalid\n",
        "    raise ValueError('invalid activation type')\n",
        "\n",
        "  return coefficient * base\n",
        "\n",
        "def activation(type, z):\n",
        "  if type == 'sigmoid':\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "  elif type == 'tanh':\n",
        "    return (torch.exp(z) - torch.exp(-z)) / (torch.exp(z) + torch.exp(-z))\n",
        "  elif type == 'relu':\n",
        "    return z * (z > 0)\n",
        "  elif type == 'lrelu':\n",
        "    z1 = z * (z > 0)\n",
        "    z2 = 0.01 * z * (z <= 0)\n",
        "    return z1 + z2\n",
        "  else:\n",
        "    raise ValueError('invalid activation type')\n",
        "\n",
        "def diff_activation(type, a):\n",
        "  if type == 'sigmoid':\n",
        "    return a * (1 - a)\n",
        "  elif type == 'tanh':\n",
        "    return 1 - a**2\n",
        "  elif type == 'relu':\n",
        "    return a > 0\n",
        "  elif type == 'lrelu':\n",
        "    a1 = a > 0\n",
        "    a2 = 0.01 * (a <= 0)\n",
        "    return a1 + a2\n",
        "  else:\n",
        "    raise ValueError('invalid activation type')\n",
        "\n",
        "def loss(y_pred, y):\n",
        "  epsilon = 1e-12\n",
        "  return -1 * torch.mean(\n",
        "      y * torch.log(y_pred + epsilon) + (1 - y) * torch.log(1 - y_pred + epsilon)\n",
        "  )\n",
        "\n",
        "def accuracy(y_pred, y):\n",
        "  answer = (y_pred >= 0.5).float()\n",
        "  return torch.mean((answer == y).float())\n",
        "\n",
        "class ThreeLayerNN:\n",
        "  # initialize parameters for this neural network\n",
        "  def __init__(self, input_size, hidden1_size, hidden2_size, output_size, activation_type):\n",
        "    self.activation = activation_type\n",
        "    self.params = {}\n",
        "\n",
        "    self.params['w1'] = initialize_weight(activation_type, input_size, hidden1_size)\n",
        "    self.params['b1'] = torch.zeros((1, hidden1_size))\n",
        "\n",
        "    self.params['w2'] = initialize_weight(activation_type, hidden1_size, hidden2_size)\n",
        "    self.params['b2'] = torch.zeros((1, hidden2_size))\n",
        "\n",
        "    self.params['w3'] = initialize_weight('sigmoid', hidden2_size, output_size)\n",
        "    self.params['b3'] = torch.zeros((1, output_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    w1, w2, w3 = self.params['w1'], self.params['w2'], self.params['w3']\n",
        "    b1, b2, b3 = self.params['b1'], self.params['b2'], self.params['b3']\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    z1 = torch.matmul(x, w1.T) + b1\n",
        "    a1 = activation(self.activation, z1)\n",
        "\n",
        "    z2 = torch.matmul(a1, w2.T) + b2\n",
        "    a2 = activation(self.activation, z2)\n",
        "\n",
        "    z3 = torch.matmul(a2, w3.T) + b3\n",
        "    a3 = activation('sigmoid', z3)\n",
        "\n",
        "    results['z1'], results['z2'], results['z3'] = z1, z2, z3\n",
        "    results['a1'], results['a2'], results['a3'] = a1, a2, a3\n",
        "\n",
        "    return results\n",
        "\n",
        "  def backward(self, x, y, forward_results):\n",
        "    w1, w2, w3 = self.params['w1'], self.params['w2'], self.params['w3']\n",
        "    b1, b2, b3 = self.params['b1'], self.params['b2'], self.params['b3']\n",
        "\n",
        "    z1, z2, z3 = forward_results['z1'], forward_results['z2'], forward_results['z3']\n",
        "    a1, a2, a3 = forward_results['a1'], forward_results['a2'], forward_results['a3']\n",
        "\n",
        "    batch_size = x.shape[0]\n",
        "\n",
        "    dz3 = (a3 - y) / batch_size\n",
        "    dw3 = torch.matmul(dz3.T, a2)\n",
        "    db3 = torch.sum(dz3, axis=0)\n",
        "\n",
        "    da2 = torch.matmul(dz3, w3)\n",
        "    dz2 = diff_activation(self.activation, a2) * da2\n",
        "    dw2 = torch.matmul(dz2.T, a1)\n",
        "    db2 = torch.sum(dz2, axis=0)\n",
        "\n",
        "    da1 = torch.matmul(dz2, w2)\n",
        "    dz1 = diff_activation(self.activation, a1) * da1\n",
        "    dw1 = torch.matmul(dz1.T, x)\n",
        "    db1 = torch.sum(dz1, axis=0)\n",
        "\n",
        "    grads = {}\n",
        "    grads['w1'], grads['w2'], grads['w3'] = dw1, dw2, dw3\n",
        "    grads['b1'], grads['b2'], grads['b3'] = db1, db2, db3\n",
        "\n",
        "    return grads\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjunQJZpYQFh",
        "colab_type": "text"
      },
      "source": [
        "### 4. Learning neural network and plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_khT_co3a6I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# learning the neural network\n",
        "def learning_nn(nn, epoch_count, lr):\n",
        "  train_losses = []\n",
        "  train_accs = []\n",
        "\n",
        "  valid_losses = []\n",
        "  valid_accs = []\n",
        "\n",
        "  for epoch in range(epoch_count):\n",
        "    # compute loss and accuracy at this epoch using training data\n",
        "    train_forward_results = nn.forward(x_train)\n",
        "    y_pred_train = train_forward_results['a3']\n",
        "    train_losses.append(loss(y_pred_train, y_train))\n",
        "    train_accs.append(accuracy(y_pred_train, y_train))\n",
        "\n",
        "    # compute loss and accuracy at this epoch using validation data\n",
        "    valid_forward_results = nn.forward(x_valid)\n",
        "    y_pred_valid = valid_forward_results['a3']\n",
        "    valid_losses.append(loss(y_pred_valid, y_valid))\n",
        "    valid_accs.append(accuracy(y_pred_valid, y_valid))\n",
        "\n",
        "    # backward propagation and update model parameters using training data\n",
        "    grads = nn.backward(x_train, y_train, train_forward_results)\n",
        "    nn.params['w1'] -= lr * grads['w1']\n",
        "    nn.params['b1'] -= lr * grads['b1']\n",
        "    nn.params['w2'] -= lr * grads['w2']\n",
        "    nn.params['b2'] -= lr * grads['b2']\n",
        "    nn.params['w3'] -= lr * grads['w3']\n",
        "    nn.params['b3'] -= lr * grads['b3']\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(f'epoch: {epoch}')\n",
        "      print(f'train loss: {train_losses[-1]}')\n",
        "      print(f'validation loss: {valid_losses[-1]}')\n",
        "      print(f'train accuracy: {train_accs[-1]}')\n",
        "      print(f'validation accuracy: {valid_accs[-1]}\\n\\n')\n",
        "\n",
        "  return train_losses, train_accs, valid_losses, valid_accs\n",
        "\n",
        "# plot the results (learning curves and table)\n",
        "def plot_results(train_losses, train_accs, valid_losses, valid_accs):\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3ZdCPEgaCCo",
        "colab_type": "text"
      },
      "source": [
        "##### `g1, g2, g3` are Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmkX6NpLaM1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "83ea9452-055d-49e9-a977-f3d1835e9b0b"
      },
      "source": [
        "nn1 = ThreeLayerNN(10000, 200, 100, 1, 'sigmoid')\n",
        "train_losses, train_accs, valid_losses, valid_accs = learning_nn(nn, epoch_count=1500, lr=0.042)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "train loss: 0.6748616099357605\n",
            "validation loss: 0.6777783632278442\n",
            "train accuracy: 0.5793573260307312\n",
            "validation accuracy: 0.5\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}