{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1186qClifTlAds1YgL6qO-WqiI7Xnd6v3",
      "authorship_tag": "ABX9TyOGohDZjkn28A5bFrLuUKhT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn5jUj5M6WgZ",
        "colab_type": "text"
      },
      "source": [
        "### 1. Load training / validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yttwiwiM6dGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "data_root = './data/horse-or-human'\n",
        "\n",
        "# define vectorize transformer\n",
        "class VectorizeTransform:\n",
        "    def __call__(self, img):\n",
        "        return torch.reshape(img, (-1, ))\n",
        "\n",
        "# compose image transformer\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    VectorizeTransform()    # for vectorizing input image\n",
        "])\n",
        "\n",
        "# load training dataset\n",
        "train_data_path = data_root + '/train'\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=2048,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# load validation dataset\n",
        "valid_data_path = data_root + '/validation'\n",
        "valid_dataset = torchvision.datasets.ImageFolder(root=valid_data_path, transform=transform)\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=2048,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMGbwXRi700K",
        "colab_type": "text"
      },
      "source": [
        "### 2. Make full batch from training / validation dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l11h0tnq8TZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_full_batch(dataloader):\n",
        "  x = torch.tensor([])\n",
        "  y = torch.tensor([], dtype=torch.long)\n",
        "\n",
        "  for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
        "    x = torch.cat([x, x_batch], dim=0)\n",
        "    y = torch.cat([y, y_batch], dim=0)\n",
        "\n",
        "  y = torch.reshape(y, (-1, 1))\n",
        "\n",
        "  return x, y\n",
        "\n",
        "# make full batch data\n",
        "x_train, y_train = make_full_batch(train_loader)\n",
        "x_valid, y_valid = make_full_batch(valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}