{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitpytorchstudyconda6cfeeef4c74546dc94441bb393b1ec01",
   "display_name": "Python 3.7.6 64-bit ('pytorch-study': conda)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO\n",
    "\n",
    "- âœ… vectorize an input image matrix into a column vector\n",
    "- compute the loss\n",
    "- compute the accuracy\n",
    "- compute the gradient of the model parameters with respect to the loss\n",
    "- update the model parameters\n",
    "- plot the results\n",
    "- Apply the number of iterations that lead to the convergence of the algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Load training/validation image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# define vectorize transformer\n",
    "class VectorizeTransform:\n",
    "    def __call__(self, img):\n",
    "        return torch.reshape(img, (-1, ))\n",
    "\n",
    "# compose image transformer\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    VectorizeTransform()    # for vectorizing input image\n",
    "])\n",
    "\n",
    "# load training dataset\n",
    "train_data_path = './data/horse-or-human/train'\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# load validation dataset\n",
    "valid_data_path = './data/horse-or-human/validation'\n",
    "valid_dataset = torchvision.datasets.ImageFolder(root=valid_data_path, transform=transform)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Learning with the gradient descent in logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "def cost(y_pred, y):\n",
    "    epsilon = 1e-12\n",
    "    return -1 * (torch.mean(\n",
    "        y * torch.log(y_pred + epsilon) + (1 - y) * torch.log(1 - y_pred + epsilon)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor(0.0838)\ntensor(0.1261)\ntensor(0.1217)\ntensor(0.1178)\ntensor(0.1143)\ntensor(0.1111)\ntensor(0.1083)\ntensor(0.1057)\ntensor(0.1034)\ntensor(0.1012)\ntensor(0.0992)\ntensor(0.0973)\ntensor(0.0955)\ntensor(0.0938)\ntensor(0.0922)\ntensor(0.0906)\ntensor(0.0890)\ntensor(0.0875)\ntensor(0.0860)\ntensor(0.0846)\ntensor(0.0832)\ntensor(0.0819)\ntensor(0.0806)\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-2dbdc758c1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# initialize parameters\n",
    "epoch_count = 100\n",
    "w = torch.zeros((1, images.shape[1]))\n",
    "b = 0\n",
    "lr = 0.001\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "batch_cost = []\n",
    "\n",
    "# start gradient descent\n",
    "for epoch in range(epoch_count):\n",
    "    for batch_idx, (x_train, y_train) in enumerate(train_loader):\n",
    "        batch_size = x_train.shape[0]\n",
    "\n",
    "        y_train = torch.reshape(y_train, (batch_size, 1))\n",
    "        y_pred_train = sigmoid(torch.matmul(x_train, w.T) + b)\n",
    "        train_cost = cost(y_pred_train, y_train)\n",
    "\n",
    "        batch_cost.append(train_cost)\n",
    "        \n",
    "        dw = (1 / batch_size) * torch.matmul((y_pred_train - y_train).T, x_train)\n",
    "        db = (1 / batch_size) * torch.sum(y_pred_train - y_train)\n",
    "\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "    print(torch.mean(torch.tensor(batch_cost)))\n",
    "    batch_cost = []\n",
    "\n",
    "    # for batch_idx, (x_test, y_test) in enumerate(valid_loader):\n",
    "    #     pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}